{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Testing delle misure di distanza al variare della precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "from cri98tj.partitioners.Geohash_partitioner import Geohash_partitioner\n",
    "from cri98tj.normalizers.FirstPoint_normalizer import FirstPoint_normalizer\n",
    "from cri98tj.selectors.RandomInformationGain_selector import RandomInformationGain_selector\n",
    "from cri98tj.distancers.Euclidean_distancer import Euclidean_distancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cri98tj.selectors.Random_selector import Random_selector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../examples/Animals Dataset/data/animals_preapred.zip').sort_values(by=[\"tid\", \"t\"])# precision=5, 50 movelet, DTW\n",
    "#df = df[[\"tid\", \"class\", \"c1\", \"c2\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "   tid class   t       c1       c2\n0    1     D   0  50.1066  3.79665\n1    1     D   4  50.1045  3.79455\n2    1     D   7  50.1111  3.79845\n3    1     D   9  50.1072  3.79845\n4    1     D  15  50.1132  3.79965",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tid</th>\n      <th>class</th>\n      <th>t</th>\n      <th>c1</th>\n      <th>c2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>50.1066</td>\n      <td>3.79665</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D</td>\n      <td>4</td>\n      <td>50.1045</td>\n      <td>3.79455</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>D</td>\n      <td>7</td>\n      <td>50.1111</td>\n      <td>3.79845</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>D</td>\n      <td>9</td>\n      <td>50.1072</td>\n      <td>3.79845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>D</td>\n      <td>15</td>\n      <td>50.1132</td>\n      <td>3.79965</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "tid_train, tid_test, _, _ = train_test_split(df.groupby(by=[\"tid\"]).max().reset_index()[\"tid\"],\n",
    "                                                        df.groupby(by=[\"tid\"]).max().reset_index()[\"class\"],\n",
    "                                                        test_size=.3,\n",
    "                                                        stratify=df.groupby(by=[\"tid\"]).max().reset_index()[\"class\"],\n",
    "                                                        random_state=3)\n",
    "\n",
    "\n",
    "spatioTemporalCols = [\"c1\", \"c2\", \"t\"]\n",
    "n_movelets=100\n",
    "n_jobs = 10\n",
    "verbose = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distanza euclidea, k=range(2,7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6d0a869433a4ec1ad451d8502ea4de0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DataDimensionalityWarning",
     "evalue": "The input data must be in this form (tid, class, time, c1, c2, partitionId)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDataDimensionalityWarning\u001B[0m                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [95]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m partitioner \u001B[38;5;241m=\u001B[39m Geohash_partitioner(precision\u001B[38;5;241m=\u001B[39mprecision, spatioTemporalColumns\u001B[38;5;241m=\u001B[39mspatioTemporalCols, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[0;32m     10\u001B[0m part \u001B[38;5;241m=\u001B[39m partitioner\u001B[38;5;241m.\u001B[39mfit_transform(df[df\u001B[38;5;241m.\u001B[39mtid\u001B[38;5;241m.\u001B[39misin(tid_train)]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m---> 11\u001B[0m shapelets \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpart\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m dist_np \u001B[38;5;241m=\u001B[39m distancer\u001B[38;5;241m.\u001B[39mfit_transform((df\u001B[38;5;241m.\u001B[39mvalues, shapelets))\n\u001B[0;32m     14\u001B[0m clf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\sklearn\\base.py:852\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    848\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    849\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    851\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 852\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    853\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\Documents\\cri98tj\\cri98tj\\selectors\\RandomInformationGain_selector.py:52\u001B[0m, in \u001B[0;36mRandomInformationGain_selector.fit\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_checkFormat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\cri98tj\\cri98tj\\selectors\\RandomInformationGain_selector.py:17\u001B[0m, in \u001B[0;36mRandomInformationGain_selector._checkFormat\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_checkFormat\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m6\u001B[39m:\n\u001B[1;32m---> 17\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m DataDimensionalityWarning(\n\u001B[0;32m     18\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe input data must be in this form (tid, class, time, c1, c2, partitionId)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mDataDimensionalityWarning\u001B[0m: The input data must be in this form (tid, class, time, c1, c2, partitionId)"
     ]
    }
   ],
   "source": [
    "from cri98tj.distancers.Euclidean_distancer import euclideanBestFitting\n",
    "\n",
    "normalizer = FirstPoint_normalizer(spatioTemporalColumns=spatioTemporalCols, fillna=None, verbose=verbose)\n",
    "selector = RandomInformationGain_selector(top_k=n_movelets, bestFittingMeasure=euclideanBestFitting, movelets_per_class=None, trajectories_for_orderline=None, n_jobs=n_jobs, spatioTemporalColumns=spatioTemporalCols, normalizer=normalizer, verbose=verbose)\n",
    "distancer = Euclidean_distancer(normalizer=normalizer, spatioTemporalColumns=spatioTemporalCols, n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "res = {}\n",
    "for precision in tqdm(range(2,7)):\n",
    "    partitioner = Geohash_partitioner(precision=precision, spatioTemporalColumns=spatioTemporalCols, verbose=verbose)\n",
    "    part = partitioner.fit_transform(df[df.tid.isin(tid_train)].values)\n",
    "    shapelets = selector.fit_transform(part)\n",
    "    dist_np = distancer.fit_transform((df.values, shapelets))\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=3, n_jobs=n_jobs, n_estimators=1000)\n",
    "\n",
    "    dist_np_df = pd.DataFrame(dist_np)\n",
    "    X = dist_np_df.drop(columns=[0]).values\n",
    "    y = dist_np_df[0].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y, random_state=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    res[str(precision)] = classification_report(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "for precisione, r in res.items():\n",
    "    print(F\"PRECISION={precisione}\")\n",
    "    print(r)\n",
    "    print(\"\\r\\n\\r\\n\\r\\n\\r\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distanza Prof"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03b41ab82fb046149d18cbacc074337c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cri98\\Documents\\cri98tj\\cri98tj\\normalizers\\normalizer_utils.py:17: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  df_pivot = df_pivot.merge(df.groupby(['partId'])['class'].max().reset_index(), on=[\"partId\"])\n",
      "C:\\Users\\cri98\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\pandas\\core\\common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "C:\\Users\\cri98\\Documents\\cri98tj\\cri98tj\\normalizers\\normalizer_utils.py:17: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  df_pivot = df_pivot.merge(df.groupby(['partId'])['class'].max().reset_index(), on=[\"partId\"])\n",
      "C:\\Users\\cri98\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\pandas\\core\\common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/141 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e48ec05b1dea46ba9e81eff030d0f6a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cri98\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\cri98\\Documents\\cri98tj\\cri98tj\\normalizers\\normalizer_utils.py:17: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  df_pivot = df_pivot.merge(df.groupby(['partId'])['class'].max().reset_index(), on=[\"partId\"])\n",
      "C:\\Users\\cri98\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\pandas\\core\\common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b539ff239fc4f8289cc495a80fe8bd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;31mTypeError\u001B[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [110]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     11\u001B[0m part \u001B[38;5;241m=\u001B[39m partitioner\u001B[38;5;241m.\u001B[39mfit_transform(df[df\u001B[38;5;241m.\u001B[39mtid\u001B[38;5;241m.\u001B[39misin(tid_train)]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m     12\u001B[0m shapelets \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mfit_transform(part)\n\u001B[1;32m---> 13\u001B[0m _, dist_np \u001B[38;5;241m=\u001B[39m \u001B[43mdistancer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshapelets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m clf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m     17\u001B[0m dist_np_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(dist_np)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cri98lj\\lib\\site-packages\\sklearn\\base.py:852\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    848\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    849\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    851\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 852\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\Documents\\cri98tj\\cri98tj\\distancers\\InterpolatedRootDistance_distancer.py:46\u001B[0m, in \u001B[0;36mInterpolatedRootDistance_distancer.transform\u001B[1;34m(self, trajectories_movelets)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, process \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(processes, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose, position\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)):\n\u001B[0;32m     45\u001B[0m     ind, col \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mresult()\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j, (val, best_i) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(col, ind)):\n\u001B[0;32m     47\u001B[0m         distances[j, i] \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m     48\u001B[0m         best_is[j, i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(best_i)\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from cri98tj.distancers.InterpolatedRootDistance_distancer import InterpolatedRootDistance_distancer, \\\n",
    "    InterpolatedRootDistanceBestFitting\n",
    "\n",
    "normalizer = FirstPoint_normalizer(spatioTemporalColumns=spatioTemporalCols, fillna=None, verbose=verbose)\n",
    "selector = RandomInformationGain_selector(top_k=n_movelets, bestFittingMeasure=InterpolatedRootDistanceBestFitting, movelets_per_class=100, trajectories_for_orderline=50, n_jobs=n_jobs, spatioTemporalColumns=spatioTemporalCols, normalizer=normalizer, verbose=verbose)\n",
    "distancer = InterpolatedRootDistance_distancer(normalizer=normalizer, spatioTemporalColumns=spatioTemporalCols, n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "res = {}\n",
    "for precision in tqdm(range(1,8)):\n",
    "    partitioner = Geohash_partitioner(precision=precision, spatioTemporalColumns=spatioTemporalCols, verbose=verbose)\n",
    "    part = partitioner.fit_transform(df[df.tid.isin(tid_train)].values)\n",
    "    shapelets = selector.fit_transform(part)\n",
    "    _, dist_np = distancer.fit_transform((df.values, shapelets))\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=3, n_jobs=n_jobs, n_estimators=1000)\n",
    "\n",
    "    dist_np_df = pd.DataFrame(dist_np)\n",
    "    X = dist_np_df.drop(columns=[0]).values\n",
    "    y = dist_np_df[0].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y, random_state=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    res[str(precision)] = classification_report(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "for precisione, r in res.items():\n",
    "    print(F\"PRECISION={precisione}\")\n",
    "    print(r)\n",
    "    print(\"\\r\\n\\r\\n\\r\\n\\r\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}